# Foreword

__By Asya Kamsky__ ([@asya999](https://twitter.com/asya999))

Databases and data management have been the one technical constant in my career since the early 1990's when I 'accidentally' got a job with a small database company. From that initial starting point and for the following two decades, databases were synonymous with entity relationships and SQL in my mind. It wasn't until someone asked me what I thought about these new-fangled and so-called 'NoSQL' databases and MongoDB in particular that I started to question the core tenets I held concerning what constituted a database.  I tried MongoDB for a small project I was developing on the side and the rest, as they say, is history. 
 
When I joined the company that created MongoDB in early 2012, the query language was simple and straightforward. It didn't include options for easy data aggregation because the general advice was 'store data the way you expect to access the data'. This was a fantastic approach for fast, low-latency real-time queries. Nevertheless, as time went on, it became clear to me that sometimes you want to answer questions that you didn't know you'd have when you were first designing an application. The choice within a MongoDB database to support this was limited. The initial attempt to address this challenge with Map-Reduce was complicated to understand and get right, requiring coding and running JavaScript, which was inefficient.  This led to a new way to aggregate data natively in the server, known as the 'The Aggregation Framework'. An aggregation organizes a set of data processing stages as a pipeline, which felt familiar and comfortable to me. It evoked how I have always processed data in files via the Unix command line, piping the output of one command into the following command's input, and so on, until the final transformed data was in the desired structure. Very quickly, 'Agg' (as I usually refer to it) became my favorite MongoDB feature for its flexibility, power, and ease of debugging.
 
Agg has come a long way in the last nine years, starting with just seven stages and a few dozen expressions operating executed against a single collection. We now have over thirty stages at our disposal to precisely control the input and output of a pipeline, including the ability to pull in additional data from other collections. We have over one hundred and fifty expressions at our fingertips to help us transform data just the way we need to, and not just for the aggregation command but also regular MongoDB queries and updates. In recent years, as the MongoDB platform has expanded to support tiered storage with a blended data set spread across both online database clusters and commodity cloud object storage, the Aggregation Framework has naturally become the underlying engine to unify this data. The query language neutrality of Aggregations perfectly couples with the burgeoning need to support multiple query languages to access a single blended data set in a modern MongoDB data platform.

The nature of data is such that we will never know up-front all the future questions we will have about it. Being able to construct complex queries (a.k.a. aggregations) about our data is critical to future success. While you can perform complex data processing in any programming language, you are comfortable with, moving the data to the 'application tier' to analyze it can be cripplingly inefficient. By enabling the analysis of data in place, you can yield tremendous advantages in time to insight. However, the prescribed language for achieving such data analysis must be intuitive and data-oriented, which the Aggregation Framework is.
 
For years, I've given talks about the power of the Aggregation Pipeline, answered thousands of questions from users about how to execute complex analysis with it, and frequently fielded requests for a comprehensive 'Aggregation Cookbook'. Of course, it would be great to have a repository of 'recipes' to solve everyday data tasks that involve more than a single-stage or expression combination. I like to think I am ideas rich, but like most people, I am time poor, and it's been hard to find the space to sit down and write something like that. Consequently, I was incredibly excited to learn that my colleague, Paul Done, had embarked head-on on a similar challenge with this book. I've also been happy to hear Paul's longer-term vision for this book to grow and evolve, addressing other prevalent best practices and examples for solving common scenarios with MongoDB Aggregations.

I hope and foresee you will find this collection of guiding principles and pipeline examples to be truly helpful in your application development and data analysis work. I look forward to seeing the book grow even further to become the cookbook that will help everyone realize the full power of their data.

